{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def trim_borders(array, top=0, bottom=0, left=0, right=0):\n",
    "    if len(array.shape) != 2:\n",
    "        raise ValueError(\"Input array must be 2D\")\n",
    "\n",
    "    return array[top : array.shape[0] - bottom, left : array.shape[1] - right]\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def fix_borders(grid):\n",
    "    y1 = grid.shape[1] - 1\n",
    "\n",
    "    for x1 in range(grid.shape[0]):\n",
    "        grid[x1, y1] = grid[x1, y1 - 1]\n",
    "        grid[x1, 0] = grid[x1, 1]\n",
    "    x2 = grid.shape[0] - 1\n",
    "    for y2 in range(grid.shape[1]):\n",
    "        grid[x2, y2] = grid[x2 - 1, y2]\n",
    "        grid[0, y2] = grid[1, y2]\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(directory, limit=-1):\n",
    "    data = []\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if limit > 0 and i == limit:\n",
    "            break\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath, header=None)\n",
    "            data.append(\n",
    "                # trim_borders(df.values, top=1, bottom=1, left=1, right=1)\n",
    "                fix_borders(trim_borders(df.values, top=1, bottom=1, left=1, right=1))\n",
    "            )\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Loaded {i} files\")\n",
    "            i += 1\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def compress_array_by_factor(original_array, factor=5):\n",
    "    old_size = original_array.shape\n",
    "    new_size = (old_size[0] // factor, old_size[1] // factor)\n",
    "\n",
    "    compressed_array = np.zeros(new_size, dtype=float)\n",
    "\n",
    "    for i in range(new_size[0]):\n",
    "        for j in range(new_size[1]):\n",
    "            block = original_array[\n",
    "                i * factor : (i + 1) * factor, j * factor : (j + 1) * factor\n",
    "            ]\n",
    "            # Average the values in the block\n",
    "            compressed_array[i, j] = np.mean(block)\n",
    "\n",
    "    return compressed_array\n",
    "\n",
    "\n",
    "def fix_data(array_of_arrays):\n",
    "    expanded_arrays = []\n",
    "    i = 0\n",
    "    for arr in array_of_arrays:\n",
    "        expanded_arrays.append(\n",
    "            compress_array_by_factor(\n",
    "                fix_borders(trim_borders(arr, top=1, bottom=1, left=1, right=1)), 4\n",
    "            )\n",
    "        )\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Fixed {i} files\")\n",
    "        # if i == 200:\n",
    "        #     break\n",
    "        i += 1\n",
    "    return np.array(expanded_arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "(55000, 32, 32)\n",
      "bool\n",
      "Epoch 1/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 184ms/step - loss: 0.3996 - val_loss: 0.2948\n",
      "Epoch 2/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 181ms/step - loss: 0.2851 - val_loss: 0.2714\n",
      "Epoch 3/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 178ms/step - loss: 0.2674 - val_loss: 0.2551\n",
      "Epoch 4/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 178ms/step - loss: 0.2536 - val_loss: 0.2465\n",
      "Epoch 5/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 179ms/step - loss: 0.2458 - val_loss: 0.2406\n",
      "Epoch 6/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 189ms/step - loss: 0.2403 - val_loss: 0.2363\n",
      "Epoch 7/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 182ms/step - loss: 0.2369 - val_loss: 0.2336\n",
      "Epoch 8/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2329 - val_loss: 0.2312\n",
      "Epoch 9/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2308 - val_loss: 0.2291\n",
      "Epoch 10/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 178ms/step - loss: 0.2292 - val_loss: 0.2274\n",
      "Epoch 11/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2275 - val_loss: 0.2262\n",
      "Epoch 12/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 183ms/step - loss: 0.2261 - val_loss: 0.2253\n",
      "Epoch 13/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 185ms/step - loss: 0.2250 - val_loss: 0.2236\n",
      "Epoch 14/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2237 - val_loss: 0.2230\n",
      "Epoch 15/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 179ms/step - loss: 0.2227 - val_loss: 0.2219\n",
      "Epoch 16/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2223 - val_loss: 0.2213\n",
      "Epoch 17/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 180ms/step - loss: 0.2212 - val_loss: 0.2207\n",
      "Epoch 18/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 179ms/step - loss: 0.2204 - val_loss: 0.2200\n",
      "Epoch 19/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 182ms/step - loss: 0.2199 - val_loss: 0.2234\n",
      "Epoch 20/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 180ms/step - loss: 0.2203 - val_loss: 0.2191\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_13\" is incompatible with the layer: expected shape=(None, 1, 1, 128), found shape=(32, 4, 4, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Encode and decode some test images\u001b[39;00m\n\u001b[0;32m     71\u001b[0m encoded_imgs \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m---> 72\u001b[0m decoded_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_imgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Plot original and reconstructed images\u001b[39;00m\n\u001b[0;32m     75\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_13\" is incompatible with the layer: expected shape=(None, 1, 1, 128), found shape=(32, 4, 4, 128)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess data\n",
    "size = 8\n",
    "true_size = size * 4\n",
    "print(\"loading...\")\n",
    "with np.load(f\"../data_fixed{size}.npz\") as set:\n",
    "    data = set[\"images\"]  # Assuming fix_data is defined elsewhere\n",
    "print(data.shape)\n",
    "print(data.dtype)\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test = train_test_split(data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN (assuming grayscale images)\n",
    "x_train = x_train.reshape((len(x_train), true_size, true_size, 1))\n",
    "x_test = x_test.reshape((len(x_test), true_size, true_size, 1))\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype(\"float32\") / 2\n",
    "x_test = x_test.astype(\"float32\") / 2\n",
    "\n",
    "# Define the CNN autoencoder architecture\n",
    "input_img = Input(shape=(true_size, true_size, 1))\n",
    "\n",
    "# Encoder\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "encoded = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Create and compile the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    ")\n",
    "\n",
    "# Create encoder and decoder models\n",
    "encoder = Model(input_img, encoded)\n",
    "decoder_input = Input(shape=(size // 8, size // 8, 128))\n",
    "decoder_output = autoencoder.layers[-7](decoder_input)\n",
    "for i in range(-6, 0):\n",
    "    decoder_output = autoencoder.layers[i](decoder_output)\n",
    "decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "# Encode and decode some test images\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Plot original and reconstructed images\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(true_size, true_size))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(true_size, true_size))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

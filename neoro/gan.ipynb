{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 938/938 [01:46<00:00,  8.80it/s, D loss=0.3750, G loss=3.0576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Results have been saved!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "# Function to generate and save images\n",
    "def save_generated_images(epoch, generator, n_samples=25):\n",
    "    z = torch.randn(n_samples, latent_dim).to(device)\n",
    "    generated_imgs = generator(z).cpu().detach()\n",
    "    \n",
    "    fig, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            axs[i, j].imshow(generated_imgs[i*5 + j].squeeze(), cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'generated_images_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Lists to store loss values\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    G_loss_epoch = 0\n",
    "    D_loss_epoch = 0\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (imgs, _) in progress_bar:\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = torch.ones(batch_size, 1).to(device)\n",
    "        fake = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), real)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        G_loss_epoch += g_loss.item()\n",
    "        D_loss_epoch += d_loss.item()\n",
    "        progress_bar.set_postfix({'D loss': f\"{d_loss.item():.4f}\", 'G loss': f\"{g_loss.item():.4f}\"})\n",
    "\n",
    "    # Calculate average losses for the epoch\n",
    "    G_loss_epoch /= len(dataloader)\n",
    "    D_loss_epoch /= len(dataloader)\n",
    "    G_losses.append(G_loss_epoch)\n",
    "    D_losses.append(D_loss_epoch)\n",
    "\n",
    "    # Generate and save images\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        save_generated_images(epoch + 1, generator)\n",
    "\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('loss_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate final set of images\n",
    "save_generated_images(num_epochs, generator, n_samples=100)\n",
    "\n",
    "print(\"Results have been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
